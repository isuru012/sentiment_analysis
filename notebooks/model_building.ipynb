{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0bd390c-882c-41ba-9d2e-17f5eb2165aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5db7f79c-b026-403d-9aaa-d4e5a7eaa86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../artifacts/sentiment_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87495405-fa99-4392-8520-5b63ddad9a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>We love this! Would you go? #talk #makememorie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm wired I know I'm George I was made that wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>What amazing service! Apple won't even talk to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  #fingerprint #Pregnancy Test https://goo.gl/h1...\n",
       "1   2      0  Finally a transparant silicon case ^^ Thanks t...\n",
       "2   3      0  We love this! Would you go? #talk #makememorie...\n",
       "3   4      0  I'm wired I know I'm George I was made that wa...\n",
       "4   5      1  What amazing service! Apple won't even talk to..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bfe7bb-2225-4f47-9062-9d9f43f11d32",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5288d2a-26d9-432a-9800-d6abdce7fe70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7920, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14629e52-213e-4b3e-bc4b-afc9cf3f3cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4830a9e9-4aa8-4a00-9687-c56353e8ae07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id       0\n",
       "label    0\n",
       "tweet    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85765b7c-ac8c-4e18-b98e-dee0956a39fb",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af54f555-35ca-4ba9-90a5-3b42e3837fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9234c14-3176-4565-8f34-b12eab142bfb",
   "metadata": {},
   "source": [
    "convert uppercase to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a759e17-5e8e-4971-8d0f-34b9aa03cce2",
   "metadata": {},
   "outputs": [],
   "source": [
    " data[\"tweet\"] = data[\"tweet\"].apply(lambda x: \" \".join(x.lower() for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f14d8d6-876a-4abb-9284-10508298349d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    #fingerprint #pregnancy test https://goo.gl/h1...\n",
       "1    finally a transparant silicon case ^^ thanks t...\n",
       "2    we love this! would you go? #talk #makememorie...\n",
       "3    i'm wired i know i'm george i was made that wa...\n",
       "4    what amazing service! apple won't even talk to...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " data[\"tweet\"].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4f9b68-d7ec-4a70-bd02-36de3f8ec541",
   "metadata": {},
   "source": [
    "remove links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "057f0653-c458-42bb-9e13-827b9f29a704",
   "metadata": {},
   "outputs": [],
   "source": [
    " data[\"tweet\"] = data[\"tweet\"].apply(lambda x: \" \".join(re.sub(r'^https?:\\/\\/.*[\\r\\n]*','',x,flags=re.MULTILINE) for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a3b26ed-b5f5-48b3-9378-a65095ad589c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    #fingerprint #pregnancy test  #android #apps #...\n",
       "1    finally a transparant silicon case ^^ thanks t...\n",
       "2    we love this! would you go? #talk #makememorie...\n",
       "3    i'm wired i know i'm george i was made that wa...\n",
       "4    what amazing service! apple won't even talk to...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " data[\"tweet\"].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c54bf36-a6ea-4718-8f5e-34dc3a571121",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tweet\"] = data[\"tweet\"].apply(lambda text: re.sub(r'https?://\\S+', '', text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d704a49e-53ca-4458-8b9d-6d2dc2dc4d70",
   "metadata": {},
   "source": [
    "remove punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3d71c07-23d9-4417-a2e5-4528b176ccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation,'')\n",
    "    return text\n",
    "\n",
    "data[\"tweet\"] = data[\"tweet\"].apply(remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e7a26a0-db78-4df4-bc9c-7c8ba88f8b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    fingerprint pregnancy test  android apps beaut...\n",
       "1    finally a transparant silicon case  thanks to ...\n",
       "2    we love this would you go talk makememories un...\n",
       "3    im wired i know im george i was made that way ...\n",
       "4    what amazing service apple wont even talk to m...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " data[\"tweet\"].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586e9b92-5607-4240-8fb2-a3a08044b365",
   "metadata": {},
   "source": [
    "remove numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f61bbfc-b42f-49e2-9169-8687470662a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tweet\"] = data['tweet'].str.replace('\\d+','',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3976cf5-ef26-473b-99b4-d39ad7ff6761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7910    perfect match instagood applewatch red instagr...\n",
       "7911    i am completely in love with the new iphone em...\n",
       "7912    tune in turn on drop out  gtd in one app  mobi...\n",
       "7913    ok so my galaxy crashed after one day now i ha...\n",
       "7914    gain followers rt this must follow me i follow...\n",
       "7915    live out loud lol liveoutloud selfie smile son...\n",
       "7916    we would like to wish you an amazing day make ...\n",
       "7917    helping my lovely  year old neighbor with her ...\n",
       "7918    finally got my smart pocket wifi stay connecte...\n",
       "7919    apple barcelona apple store bcn barcelona trav...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"tweet\"].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1daf2acd-b1da-49f6-993c-be91a7a1c4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 60"
   ]
  },
  {
   "cell_type": "raw",
   "id": "130a2404-8b62-4b23-b115-ba8aed5d11f6",
   "metadata": {},
   "source": [
    "remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec9e59be-f3a5-4fe3-af1f-beb5d31adaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 4.0 MB/s eta 0:00:00\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2026.1.15-cp310-cp310-win_amd64.whl (277 kB)\n",
      "     -------------------------------------- 277.8/277.8 kB 2.4 MB/s eta 0:00:00\n",
      "Collecting click\n",
      "  Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "     ---------------------------------------- 108.3/108.3 kB ? eta 0:00:00\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Installing collected packages: tqdm, regex, click, nltk\n",
      "Successfully installed click-8.3.1 nltk-3.9.2 regex-2026.1.15 tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)'))': /simple/nltk/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)'))': /simple/nltk/\n",
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92b4bdf2-0d47-4b70-885d-0bb080bd4cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a57ebc2-dfd0-43a2-ba02-37863aaf0fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to ../static/model...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords',download_dir='../static/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f0cd708-a64c-4614-b0ab-1407dbf4ab46",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../static/model/corpora/stopwords/english', 'r') as file:\n",
    "    sw = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3c0e015-febf-48fb-8fef-236030240f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d7cf3a4-8ab9-4c1f-b05d-2a2772a608bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tweet\"] = data[\"tweet\"].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f552497f-913e-456a-8ea4-26393fbbdeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    fingerprint pregnancy test android apps beauti...\n",
       "1    finally transparant silicon case thanks uncle ...\n",
       "2    love would go talk makememories unplug relax i...\n",
       "3    im wired know im george made way iphone cute d...\n",
       "4    amazing service apple wont even talk question ...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " data[\"tweet\"].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeeaa5d-7a5b-4779-8ac7-f83deb768926",
   "metadata": {},
   "source": [
    "stemming(take the base word of the words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff905e29-a6b3-4c02-ad99-e199d1fc6cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "996ae543-52df-4a56-9a2f-93542e3721f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tweet\"] = data[\"tweet\"].apply(lambda x: \" \".join(ps.stem(x) for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ebaa106b-2fc9-4888-830c-9a670d8d4175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    fingerprint pregnanc test android app beauti c...\n",
       "1    final transpar silicon case thank uncl yay son...\n",
       "2    love would go talk makememori unplug relax iph...\n",
       "3    im wire know im georg made way iphon cute dave...\n",
       "4    amaz servic appl wont even talk question unles...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"tweet\"].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1a1ce3-3ce6-4237-8267-f87eeef99e82",
   "metadata": {},
   "source": [
    "## Building Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac0d21b3-e496-49e8-b34d-b2a6a4240520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "vocab = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ffba41e5-d537-4009-a52a-3942e03162c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a8d4a06-231b-4143-9547-204e3775d897",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in data['tweet']:\n",
    "    vocab.update(sentence.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e63aa87d-0447-40ae-bed9-b31d4f9dd2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15904"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "30f0928f-441f-4c8b-aaa2-8549ad633ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7920, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc438d3f-1875-4392-8c55-3979d8befd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [key for key in vocab if vocab[key]>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c5ea43ff-ef51-4515-addc-c6f4201f560f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1146"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3547aaba-5dc0-4eea-9f97-2f1a0c23c446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Step 1: Vectorize tweets (TF-IDF)\n",
    "vectorizer = TfidfVectorizer(vocabulary=tokens)  # use your filtered tokens\n",
    "X = vectorizer.fit_transform(data['tweet'])\n",
    "y = data['label']  # your target variable\n",
    "\n",
    "# Step 2: Select top K features using Chi-Square\n",
    "selector = SelectKBest(chi2, k=500)  # keep top 500 most informative features\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "# Optional: Get selected feature names\n",
    "tokens = [feature for feature, selected in zip(vectorizer.get_feature_names_out(), selector.get_support()) if selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0e39a5bc-e635-4e34-b316-b71007c4e6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fe547f05-5ad7-4ae1-8c5a-e1da91eb7080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['android',\n",
       " 'beauti',\n",
       " 'cute',\n",
       " 'health',\n",
       " 'iger',\n",
       " 'iphoneonli',\n",
       " 'iphonesia',\n",
       " 'iphon',\n",
       " 'final',\n",
       " 'case',\n",
       " 'yay',\n",
       " 'soni',\n",
       " 'xperia',\n",
       " 'love',\n",
       " 'would',\n",
       " 'go',\n",
       " 'relax',\n",
       " 'smartphon',\n",
       " 'connect',\n",
       " 'im',\n",
       " 'know',\n",
       " 'home',\n",
       " 'amaz',\n",
       " 'servic',\n",
       " 'appl',\n",
       " 'wont',\n",
       " 'even',\n",
       " 'pay',\n",
       " 'stupid',\n",
       " 'support',\n",
       " 'softwar',\n",
       " 'updat',\n",
       " 'fuck',\n",
       " 'phone',\n",
       " 'time',\n",
       " 'happi',\n",
       " 'instap',\n",
       " 'instadaili',\n",
       " 'xperiaz',\n",
       " 'new',\n",
       " 'type',\n",
       " 'charger',\n",
       " 'cabl',\n",
       " 'amazon',\n",
       " 'newyear',\n",
       " 'start',\n",
       " 'technolog',\n",
       " 'iphonex',\n",
       " 'shop',\n",
       " 'photo',\n",
       " 'fun',\n",
       " 'selfi',\n",
       " 'camera',\n",
       " 'picoftheday',\n",
       " 'sun',\n",
       " 'instagood',\n",
       " 'boy',\n",
       " 'make',\n",
       " 'ipod',\n",
       " 'dont',\n",
       " 'color',\n",
       " 'crash',\n",
       " 'everi',\n",
       " 'need',\n",
       " 'realli',\n",
       " 'drop',\n",
       " 'anoth',\n",
       " 'lol',\n",
       " 'work',\n",
       " 'batteri',\n",
       " 'charg',\n",
       " 'dead',\n",
       " 'saturday',\n",
       " 'summer',\n",
       " 'share',\n",
       " 'want',\n",
       " 'instagram',\n",
       " 'photooftheday',\n",
       " 'tweegram',\n",
       " 'reason',\n",
       " 'one',\n",
       " 'suck',\n",
       " 'agre',\n",
       " 'fact',\n",
       " 'store',\n",
       " 'screen',\n",
       " 'art',\n",
       " 'dear',\n",
       " 'friend',\n",
       " 'email',\n",
       " 'seem',\n",
       " 'pie',\n",
       " 'ive',\n",
       " 'day',\n",
       " 'button',\n",
       " 'broke',\n",
       " 'goe',\n",
       " 'complet',\n",
       " 'black',\n",
       " 'get',\n",
       " 'text',\n",
       " 'cant',\n",
       " 'wall',\n",
       " 'galaxi',\n",
       " 'samsung',\n",
       " 'patent',\n",
       " 'mess',\n",
       " 'havent',\n",
       " 'noth',\n",
       " 'lose',\n",
       " 'pic',\n",
       " 'kill',\n",
       " 'someon',\n",
       " 'hateappl',\n",
       " 'flower',\n",
       " 'must',\n",
       " 'twitch',\n",
       " 'game',\n",
       " 'io',\n",
       " 'live',\n",
       " 'laugh',\n",
       " 'life',\n",
       " 'food',\n",
       " 'instago',\n",
       " 'instahub',\n",
       " 'dog',\n",
       " 'famili',\n",
       " 'bestfriend',\n",
       " 'sunset',\n",
       " 'sky',\n",
       " 'gift',\n",
       " 'receiv',\n",
       " 'note',\n",
       " 'mani',\n",
       " 'delet',\n",
       " 'itun',\n",
       " 'freak',\n",
       " 'tech',\n",
       " 'bull',\n",
       " 'smile',\n",
       " 'let',\n",
       " 'sunday',\n",
       " 'ootd',\n",
       " 'fashion',\n",
       " 'blackandwhit',\n",
       " 'film',\n",
       " 'follow',\n",
       " 'pink',\n",
       " 'sweet',\n",
       " 'sexi',\n",
       " 'week',\n",
       " 'iphoneplu',\n",
       " 'photographi',\n",
       " 'natur',\n",
       " 'tree',\n",
       " 'travel',\n",
       " 'cut',\n",
       " 'program',\n",
       " 'christma',\n",
       " 'girl',\n",
       " 'instacool',\n",
       " 'free',\n",
       " 'appstor',\n",
       " 'joy',\n",
       " 'peac',\n",
       " 'babi',\n",
       " 'pet',\n",
       " 'news',\n",
       " 'funni',\n",
       " 'hate',\n",
       " 'use',\n",
       " 'think',\n",
       " 'product',\n",
       " 'friday',\n",
       " 'call',\n",
       " 'holiday',\n",
       " 'newyork',\n",
       " 'birthday',\n",
       " 'comput',\n",
       " 'serious',\n",
       " 'month',\n",
       " 'job',\n",
       " 'actual',\n",
       " 'replac',\n",
       " 'that',\n",
       " 'still',\n",
       " 'rt',\n",
       " 'droid',\n",
       " 'cool',\n",
       " 'run',\n",
       " 'beach',\n",
       " 'yet',\n",
       " 'arriv',\n",
       " 'gain',\n",
       " 'everyon',\n",
       " 'sougofollow',\n",
       " 'ff',\n",
       " 'iphoneographi',\n",
       " 'mobil',\n",
       " 'user',\n",
       " 'date',\n",
       " 'instamood',\n",
       " 'hot',\n",
       " 'red',\n",
       " 'id',\n",
       " 'lost',\n",
       " 'broken',\n",
       " 'light',\n",
       " 'gold',\n",
       " 'reset',\n",
       " 'sorri',\n",
       " 'white',\n",
       " 'chill',\n",
       " 'cover',\n",
       " 'followsunday',\n",
       " 'followback',\n",
       " 'teamfollowback',\n",
       " 'retweet',\n",
       " 'ya',\n",
       " 'thing',\n",
       " 'alreadi',\n",
       " 'problem',\n",
       " 'issu',\n",
       " 'abl',\n",
       " 'put',\n",
       " 'devic',\n",
       " 'enjoy',\n",
       " 'gamer',\n",
       " 'wrong',\n",
       " 'right',\n",
       " 'today',\n",
       " 'fuckyou',\n",
       " 'never',\n",
       " 'bug',\n",
       " 'present',\n",
       " 'mom',\n",
       " 'quot',\n",
       " 'word',\n",
       " 'repair',\n",
       " 'hour',\n",
       " 'everyth',\n",
       " 'compani',\n",
       " 'model',\n",
       " 'cd',\n",
       " 'didnt',\n",
       " 'spring',\n",
       " 'galaxynot',\n",
       " 'valentin',\n",
       " 'much',\n",
       " 'say',\n",
       " 'took',\n",
       " 'download',\n",
       " 'last',\n",
       " 'min',\n",
       " 'rid',\n",
       " 'annoy',\n",
       " 'buy',\n",
       " 'version',\n",
       " 'style',\n",
       " 'bestoftheday',\n",
       " 'pretti',\n",
       " 'send',\n",
       " 'turn',\n",
       " 'imessag',\n",
       " 'shotoniphon',\n",
       " 'photograph',\n",
       " 'sync',\n",
       " 'second',\n",
       " 'fml',\n",
       " 'nice',\n",
       " 'wait',\n",
       " 'doesnt',\n",
       " 'liter',\n",
       " 'cri',\n",
       " 'contact',\n",
       " 'laptop',\n",
       " 'best',\n",
       " 'fruit',\n",
       " 'mac',\n",
       " 'told',\n",
       " 'stop',\n",
       " 'gear',\n",
       " 'well',\n",
       " 'past',\n",
       " 'capetownsup',\n",
       " 'sup',\n",
       " 'surf',\n",
       " 'capetown',\n",
       " 'half',\n",
       " 'stuff',\n",
       " 'excit',\n",
       " 'piss',\n",
       " 'offici',\n",
       " 'keyboard',\n",
       " 'okay',\n",
       " 'though',\n",
       " 'enough',\n",
       " 'th',\n",
       " 'refus',\n",
       " 'jj',\n",
       " 'makeup',\n",
       " 'portrait',\n",
       " 'password',\n",
       " 'prophet',\n",
       " 'husband',\n",
       " 'kindl',\n",
       " 'there',\n",
       " 'least',\n",
       " 'old',\n",
       " 'followm',\n",
       " 'likelik',\n",
       " 'swag',\n",
       " 'cat',\n",
       " 'sick',\n",
       " 'bullshit',\n",
       " 'welcom',\n",
       " 'os',\n",
       " 'throw',\n",
       " 'take',\n",
       " 'two',\n",
       " 'offer',\n",
       " 'middl',\n",
       " 'access',\n",
       " 'account',\n",
       " 'citi',\n",
       " 'awesom',\n",
       " 'accessori',\n",
       " 'whole',\n",
       " 'playlist',\n",
       " 'gadget',\n",
       " 'count',\n",
       " 'tl',\n",
       " 'drive',\n",
       " 'nyc',\n",
       " 'tattoo',\n",
       " 'instal',\n",
       " 'sale',\n",
       " 'motorola',\n",
       " 'unitedst',\n",
       " 'guitarplay',\n",
       " 'crap',\n",
       " 'icloud',\n",
       " 'angri',\n",
       " 'freez',\n",
       " 'ever',\n",
       " 'sinc',\n",
       " 'tri',\n",
       " 'wouldnt',\n",
       " 'blue',\n",
       " 'ig',\n",
       " 'orang',\n",
       " 'lock',\n",
       " 'colleg',\n",
       " 'chocol',\n",
       " 'shit',\n",
       " 'ador',\n",
       " 'nofilt',\n",
       " 'drink',\n",
       " 'андроид',\n",
       " 'bestpric',\n",
       " 'caus',\n",
       " 'manag',\n",
       " 'bless',\n",
       " 'could',\n",
       " 'system',\n",
       " 'morn',\n",
       " 'nike',\n",
       " 'sell',\n",
       " 'mad',\n",
       " 'headphon',\n",
       " 'ebay',\n",
       " 'fix',\n",
       " 'oneplu',\n",
       " 'chang',\n",
       " 'wanna',\n",
       " 'your',\n",
       " 'tell',\n",
       " 'backup',\n",
       " 'peopl',\n",
       " 'anyon',\n",
       " 'els',\n",
       " 'number',\n",
       " 'possibl',\n",
       " 'frustrat',\n",
       " 'rhyme',\n",
       " 'restor',\n",
       " 'igdaili',\n",
       " 'healthi',\n",
       " 'ugh',\n",
       " 'bc',\n",
       " 'sonyphoto',\n",
       " 'danc',\n",
       " 'phonecas',\n",
       " 'might',\n",
       " 'map',\n",
       " 'hello',\n",
       " 'sent',\n",
       " 'went',\n",
       " 'wasnt',\n",
       " 'insta',\n",
       " 'newphon',\n",
       " 'vsco',\n",
       " 'finger',\n",
       " 'anymor',\n",
       " 'instalik',\n",
       " 'hateiphon',\n",
       " 'better',\n",
       " 'kiss',\n",
       " 'fresh',\n",
       " 'inspir',\n",
       " 'luxuri',\n",
       " 'toy',\n",
       " 'decor',\n",
       " 'theyr',\n",
       " 'wipe',\n",
       " 'instalov',\n",
       " 'storag',\n",
       " 'shitti',\n",
       " 'wast',\n",
       " 'switch',\n",
       " 'load',\n",
       " 'sue',\n",
       " 'teamandroid',\n",
       " 'ly',\n",
       " 'ill',\n",
       " 'coupl',\n",
       " 'forc',\n",
       " 'appar',\n",
       " 'ago',\n",
       " 'said',\n",
       " 'tshirt',\n",
       " 'tbt',\n",
       " 'screw',\n",
       " 'useless',\n",
       " 'weekend',\n",
       " 'japan',\n",
       " 'applesuck',\n",
       " 'everyday',\n",
       " 'discount',\n",
       " 'data',\n",
       " 'spent',\n",
       " 'puppi',\n",
       " 'iphonecas',\n",
       " 'left',\n",
       " 'mean',\n",
       " 'mayb',\n",
       " 'california',\n",
       " 'repost',\n",
       " 'gone',\n",
       " 'break',\n",
       " 'trip',\n",
       " 'slow',\n",
       " 'wtf',\n",
       " 'anyth',\n",
       " 'cuz',\n",
       " 'gonna',\n",
       " 'die',\n",
       " 'thankyou',\n",
       " 'messag',\n",
       " 'vocat',\n",
       " 'thailand',\n",
       " 'khaoko',\n",
       " 'ilc',\n",
       " 'psn',\n",
       " 'cost',\n",
       " 'crack',\n",
       " 'stuck',\n",
       " 'blow',\n",
       " 'piec',\n",
       " 'remov',\n",
       " 'secur',\n",
       " 'figur',\n",
       " 'hair',\n",
       " 'asshol',\n",
       " 'wors',\n",
       " 'credit',\n",
       " 'appoint',\n",
       " 'geniu',\n",
       " 'glad',\n",
       " 'decid',\n",
       " 'current',\n",
       " 'ok',\n",
       " 'worst',\n",
       " 'ear',\n",
       " 'shut',\n",
       " 'mirror',\n",
       " 'longer',\n",
       " 'either',\n",
       " 'sure',\n",
       " 'foodporn',\n",
       " 'isnt',\n",
       " 'worth',\n",
       " 'safari',\n",
       " 'canon',\n",
       " 'street',\n",
       " 'applesupport',\n",
       " 'later',\n",
       " 'error',\n",
       " 'correct',\n",
       " 'report']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f6f52b09-2abf-430c-abde-4eb91f45fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vocabulary(lines, filename):\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename, 'w', encoding=\"utf-8\")\n",
    "    file.write(data)\n",
    "    file.close()\n",
    "\n",
    "save_vocabulary(tokens, '../static/model/vocabulary.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6813543e-afa4-46cb-b245-ccd9d8dc6d2d",
   "metadata": {},
   "source": [
    "### Dividing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "665aa55c-4f29-459f-9bf5-6f0a8524a9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['tweet']\n",
    "y =data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d3132582-a0c5-455a-aed7-18dd4c16e190",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeda6ce6-33e6-43d3-a9c5-4c324f5e915b",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "51ea1d7c-d7e8-4d53-89ab-323321d23863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer(ds, vocabulary):\n",
    "    vectorized_lst = []\n",
    "    \n",
    "    for sentence in ds:\n",
    "        sentence_lst = np.zeros(len(vocabulary))\n",
    "        \n",
    "        for i in range(len(vocabulary)):\n",
    "            if vocabulary[i] in sentence.split():\n",
    "                sentence_lst[i] = 1\n",
    "        \n",
    "        vectorized_lst.append(sentence_lst)\n",
    "    \n",
    "    vectorized_lst_new = np.asarray(vectorized_lst, dtype=np.float32)\n",
    "    return vectorized_lst_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b8658b3f-37d5-498d-a2ab-b007e98a9763",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_x_train=vectorizer(x_train,tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0382a691-646a-4849-80a5-d547c42517e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], shape=(6336, 500), dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d82c8f75-d4e5-43e4-9db2-ebf4de32a0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_x_test=vectorizer(x_test,tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5eabc2be-6d70-4db0-be61-59198ddb12ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], shape=(1584, 500), dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37595c7-0820-42bd-bdc9-14ede07b1d1d",
   "metadata": {},
   "source": [
    "### Handle imbalanced dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5ee737bd-1647-4458-80fc-dad0bdbf0862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9484, 500) (9484,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "vectorized_x_train_smote, y_train_smote = smote.fit_resample(vectorized_x_train, y_train)\n",
    "print(vectorized_x_train_smote.shape, y_train_smote.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b11b117d-1205-457d-917a-d7b1adde8c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], shape=(9484, 500), dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_x_train_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "15ec795f-581e-4852-9787-e4b6257a3abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       1\n",
       "       ..\n",
       "9479    1\n",
       "9480    1\n",
       "9481    1\n",
       "9482    1\n",
       "9483    1\n",
       "Name: label, Length: 9484, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3f5a8560-4997-48b9-81c0-5650b99bd7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], shape=(1584, 500), dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1be9b0a5-7f73-44bb-80ce-06ad841b3853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4896    0\n",
       "7539    1\n",
       "1677    0\n",
       "1964    0\n",
       "3025    0\n",
       "       ..\n",
       "1419    0\n",
       "3939    0\n",
       "7834    1\n",
       "5137    1\n",
       "4434    0\n",
       "Name: label, Length: 1584, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4e8ea8-2482-4879-b6e4-22dea0213445",
   "metadata": {},
   "source": [
    "## Model building and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bb509cdf-69ae-4b63-a0e0-6e4c8313fabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9dba99c5-84ea-46e1-8c99-65b2d0338029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "def training_scores(y_act, y_pred):\n",
    "    acc = round(accuracy_score(y_act, y_pred), 3)\n",
    "    pr = round(precision_score(y_act, y_pred), 3)\n",
    "    rec = round(recall_score(y_act, y_pred), 3)\n",
    "    f1 = round(f1_score(y_act, y_pred), 3)\n",
    "    print(f'Training Scores:\\n\\tAccuracy = {acc}\\n\\tPrecision = {pr}\\n\\tRecall = {rec}\\n\\tF1-Score = {f1}')\n",
    "\n",
    "def validation_scores(y_act, y_pred):\n",
    "    acc = round(accuracy_score(y_act, y_pred), 3)\n",
    "    pr = round(precision_score(y_act, y_pred), 3)\n",
    "    rec = round(recall_score(y_act, y_pred), 3)\n",
    "    f1 = round(f1_score(y_act, y_pred), 3)\n",
    "    print(f'Testing Scores:\\n\\tAccuracy = {acc}\\n\\tPrecision = {pr}\\n\\tRecall = {rec}\\n\\tF1-Score = {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee6d0de-8d44-4ba4-a215-87bfcff3b6fd",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "81433832-9c9f-4b25-98c2-99f762d4356c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores:\n",
      "\tAccuracy = 0.904\n",
      "\tPrecision = 0.872\n",
      "\tRecall = 0.947\n",
      "\tF1-Score = 0.908\n",
      "Testing Scores:\n",
      "\tAccuracy = 0.875\n",
      "\tPrecision = 0.717\n",
      "\tRecall = 0.896\n",
      "\tF1-Score = 0.796\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(vectorized_x_train_smote,y_train_smote)\n",
    "\n",
    "y_train_pred =lr.predict(vectorized_x_train_smote)\n",
    "\n",
    "y_test_pred = lr.predict(vectorized_x_test)\n",
    "\n",
    "training_scores(y_train_smote,y_train_pred)\n",
    "\n",
    "validation_scores(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbb4251-063a-49db-b498-5476eb7f3026",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7841c1d7-4d03-414c-b005-07ad06e077f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores:\n",
      "\tAccuracy = 0.891\n",
      "\tPrecision = 0.854\n",
      "\tRecall = 0.944\n",
      "\tF1-Score = 0.897\n",
      "Testing Scores:\n",
      "\tAccuracy = 0.879\n",
      "\tPrecision = 0.712\n",
      "\tRecall = 0.938\n",
      "\tF1-Score = 0.809\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(vectorized_x_train_smote,y_train_smote)\n",
    "\n",
    "y_train_pred =mnb.predict(vectorized_x_train_smote)\n",
    "\n",
    "y_test_pred = mnb.predict(vectorized_x_test)\n",
    "\n",
    "training_scores(y_train_smote,y_train_pred)\n",
    "\n",
    "validation_scores(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866cb7ce-0342-489a-be23-e82e6e2303a3",
   "metadata": {},
   "source": [
    "## Desicison Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3a61db9a-fb4a-4cb2-8fc9-164f011ebd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores:\n",
      "\tAccuracy = 0.994\n",
      "\tPrecision = 0.993\n",
      "\tRecall = 0.995\n",
      "\tF1-Score = 0.994\n",
      "Testing Scores:\n",
      "\tAccuracy = 0.816\n",
      "\tPrecision = 0.685\n",
      "\tRecall = 0.6\n",
      "\tF1-Score = 0.64\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(vectorized_x_train_smote,y_train_smote)\n",
    "\n",
    "y_train_pred =dt.predict(vectorized_x_train_smote)\n",
    "\n",
    "y_test_pred = dt.predict(vectorized_x_test)\n",
    "\n",
    "training_scores(y_train_smote,y_train_pred)\n",
    "\n",
    "validation_scores(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa73d10-ca50-4d91-8b08-86cbbce6eb70",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "216d182f-0b54-4413-a425-f5a42a848f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores:\n",
      "\tAccuracy = 0.994\n",
      "\tPrecision = 0.992\n",
      "\tRecall = 0.996\n",
      "\tF1-Score = 0.994\n",
      "Testing Scores:\n",
      "\tAccuracy = 0.856\n",
      "\tPrecision = 0.771\n",
      "\tRecall = 0.671\n",
      "\tF1-Score = 0.718\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(vectorized_x_train_smote,y_train_smote)\n",
    "\n",
    "y_train_pred =rf.predict(vectorized_x_train_smote)\n",
    "\n",
    "y_test_pred = rf.predict(vectorized_x_test)\n",
    "\n",
    "training_scores(y_train_smote,y_train_pred)\n",
    "\n",
    "validation_scores(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ff57ae-5238-4882-a5ea-a41744f68291",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1f92413a-7172-4e2d-a5e0-d2ca0d476a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores:\n",
      "\tAccuracy = 0.953\n",
      "\tPrecision = 0.927\n",
      "\tRecall = 0.983\n",
      "\tF1-Score = 0.954\n",
      "Testing Scores:\n",
      "\tAccuracy = 0.887\n",
      "\tPrecision = 0.75\n",
      "\tRecall = 0.88\n",
      "\tF1-Score = 0.809\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "\n",
    "svm.fit(vectorized_x_train_smote,y_train_smote)\n",
    "\n",
    "y_train_pred =svm.predict(vectorized_x_train_smote)\n",
    "\n",
    "y_test_pred = svm.predict(vectorized_x_test)\n",
    "\n",
    "training_scores(y_train_smote,y_train_pred)\n",
    "\n",
    "validation_scores(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "38b16e3a-93c2-4330-96e8-db9367c16ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../static/model/model.pickle','wb') as file:\n",
    "    pickle.dump(svm,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6116fb6-a445-4761-8f28-ce6a221f6dee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
